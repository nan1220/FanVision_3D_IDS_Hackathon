{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bb53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0661286d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopen3d\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mo3d\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyslam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, io, slam, dense\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from pyslam import config, io, slam, dense\n",
    "\n",
    "def run_slam_on_video(video_path, cam_calib_path, output_map_path=None):\n",
    "    \"\"\"\n",
    "    Run pySLAM full SLAM (with dense mapping) on a video,\n",
    "    return camera trajectory and dense point cloud.\n",
    "    \"\"\"\n",
    "    # 1. set up configuration\n",
    "    cfg = config.Config(\"config.yaml\")\n",
    "    # override dataset to VIDEO\n",
    "    cfg[\"DATASET\"][\"type\"] = \"VIDEO_DATASET\"\n",
    "    cfg[\"DATASET\"][\"VIDEO_DATASET\"][\"path\"] = video_path\n",
    "    cfg[\"DATASET\"][\"VIDEO_DATASET\"][\"camera_settings\"] = cam_calib_path\n",
    "    # enable volumetric / dense mapping\n",
    "    cfg[\"GLOBAL_PARAMETERS\"][\"kUseVolumetricIntegration\"] = True\n",
    "    # pick TSDF or Gaussian splatting method\n",
    "    cfg[\"GLOBAL_PARAMETERS\"][\"kVolumetricIntegrationType\"] = \"TSDF\"\n",
    "    # (optionally) enable depth prediction (if using monocular)\n",
    "    cfg[\"GLOBAL_PARAMETERS\"][\"kUseDepthEstimatorInFrontEnd\"] = True\n",
    "\n",
    "    # 2. run SLAM\n",
    "    slam_system = slam.SLAM(cfg)\n",
    "    slam_system.run()  # blocks until finishes (or user quits)\n",
    "\n",
    "    # 3. extract dense map / point cloud\n",
    "    dense_integrator = slam_system.get_dense_integrator()\n",
    "    # get a point cloud (Open3D format) or numpy\n",
    "    pcd = dense_integrator.get_point_cloud()\n",
    "\n",
    "    if output_map_path is not None:\n",
    "        o3d.io.write_point_cloud(output_map_path, pcd)\n",
    "    return slam_system, pcd\n",
    "\n",
    "def estimate_scene_bbox(pcd: o3d.geometry.PointCloud):\n",
    "    \"\"\"\n",
    "    Given a point cloud, compute axis-aligned bounding box (or oriented bounding box),\n",
    "    return length, width, height.\n",
    "    \"\"\"\n",
    "    # Option A: axis-aligned bounding box\n",
    "    aabb = pcd.get_axis_aligned_bounding_box()\n",
    "    dims = aabb.get_extent()  # (x_size, y_size, z_size)\n",
    "    return dims, aabb\n",
    "\n",
    "def main():\n",
    "    video_path = \"input_scene.mp4\"\n",
    "    cam_calib = \"settings/my_camera.yaml\"\n",
    "    output_map = \"dense_map.ply\"\n",
    "\n",
    "    slam_sys, pcd = run_slam_on_video(video_path, cam_calib, output_map)\n",
    "    dims, bbox = estimate_scene_bbox(pcd)\n",
    "    print(\"Scene bounding box dims (units):\", dims)\n",
    "\n",
    "    # If you know one real dimension (e.g. width of door = 0.9 m),\n",
    "    # you can compute scale factor to convert units → meters\n",
    "    known_scene_distance = 0.9  # meters\n",
    "    measured_units = dims[0]  # assume x-direction corresponds\n",
    "    scale = known_scene_distance / measured_units\n",
    "    dims_meters = dims * scale\n",
    "    print(\"Estimated bounding dims in meters:\", dims_meters)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a390757a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyslam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, slam\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_slam\u001b[39m(video_path: \u001b[38;5;28mstr\u001b[39m, calib_path: \u001b[38;5;28mstr\u001b[39m) -> np.ndarray:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyslam import config, slam\n",
    "\n",
    "def run_slam(video_path: str, calib_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Run pySLAM on a video and return a 3D point cloud as a NumPy array.\n",
    "    (No visualization, no Open3D)\n",
    "    \"\"\"\n",
    "    cfg = config.Config(\"config.yaml\")\n",
    "\n",
    "    # --- configure dataset ---\n",
    "    cfg[\"DATASET\"][\"type\"] = \"VIDEO_DATASET\"\n",
    "    cfg[\"DATASET\"][\"VIDEO_DATASET\"][\"path\"] = video_path\n",
    "    cfg[\"DATASET\"][\"VIDEO_DATASET\"][\"camera_settings\"] = calib_path\n",
    "\n",
    "    # --- enable dense reconstruction ---\n",
    "    cfg[\"GLOBAL_PARAMETERS\"][\"kUseVolumetricIntegration\"] = True\n",
    "    cfg[\"GLOBAL_PARAMETERS\"][\"kVolumetricIntegrationType\"] = \"TSDF\"\n",
    "    cfg[\"GLOBAL_PARAMETERS\"][\"kUseDepthEstimatorInFrontEnd\"] = True\n",
    "\n",
    "    # --- run SLAM ---\n",
    "    slam_system = slam.SLAM(cfg)\n",
    "    slam_system.run()\n",
    "\n",
    "    # --- get point cloud (Nx3 numpy array) ---\n",
    "    dense_integrator = slam_system.get_dense_integrator()\n",
    "    points = dense_integrator.get_points_numpy()  # suppose it returns np.ndarray\n",
    "    return points\n",
    "\n",
    "\n",
    "def compute_scene_size(points: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute simple bounding box dimensions (length, width, height)\n",
    "    from a NumPy point cloud array of shape (N, 3).\n",
    "    \"\"\"\n",
    "    if points is None or len(points) == 0:\n",
    "        raise ValueError(\"No points reconstructed from SLAM.\")\n",
    "\n",
    "    # Remove NaNs or infs\n",
    "    valid = np.isfinite(points).all(axis=1)\n",
    "    points = points[valid]\n",
    "\n",
    "    # Compute min/max per axis\n",
    "    mins = np.min(points, axis=0)\n",
    "    maxs = np.max(points, axis=0)\n",
    "\n",
    "    dims = maxs - mins  # [dx, dy, dz]\n",
    "    return dims, mins, maxs\n",
    "\n",
    "\n",
    "def scale_to_real_world(dims, known_real_length=None, known_axis=0):\n",
    "    \"\"\"\n",
    "    Optional: rescale dimensions to meters if one known real-world length is given.\n",
    "    known_axis = 0 (x), 1 (y), or 2 (z)\n",
    "    \"\"\"\n",
    "    if known_real_length is None:\n",
    "        return dims, 1.0\n",
    "    scale = known_real_length / dims[known_axis]\n",
    "    return dims * scale, scale\n",
    "\n",
    "\n",
    "def main():\n",
    "    video_path = \"input_scene.mp4\"\n",
    "    calib_path = \"camera.yaml\"  # your calibration file\n",
    "\n",
    "    print(\"Running SLAM... (this can take a while)\")\n",
    "    points = run_slam(video_path, calib_path)\n",
    "\n",
    "    print(f\"Reconstructed {len(points)} 3D points.\")\n",
    "    dims, mins, maxs = compute_scene_size(points)\n",
    "\n",
    "    # Optional: if you know a real object’s size to fix scale\n",
    "    # e.g., wall width known = 3.2 meters\n",
    "    dims_m, scale = scale_to_real_world(dims, known_real_length=3.2, known_axis=0)\n",
    "\n",
    "    print(\"Bounding box (in SLAM units):\", dims)\n",
    "    print(f\"Scale factor: {scale:.3f}\")\n",
    "    print(\"Estimated scene size (meters):\")\n",
    "    print(f\"  Length (x): {dims_m[0]:.2f} m\")\n",
    "    print(f\"  Width  (y): {dims_m[1]:.2f} m\")\n",
    "    print(f\"  Height (z): {dims_m[2]:.2f} m\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
